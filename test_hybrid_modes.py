#!/usr/bin/env python3
"""
æµ‹è¯•HybridMambaçš„ä¸åŒæ··åˆæ¨¡å¼
"""

import torch
from HybridMamba import HybridMamba

def test_hybrid_modes():
    """æµ‹è¯•ä¸åŒçš„æ··åˆæ¨¡å¼"""
    
    print("=" * 60)
    print("æµ‹è¯• HybridMamba çš„ä¸åŒæ··åˆæ¨¡å¼")
    print("=" * 60)
    
    modes = ['alternate', 'mamba_first', 'attention_first', 'all_mamba', 'all_attention']
    
    for mode in modes:
        print(f"\nğŸ” æµ‹è¯•æ¨¡å¼: {mode}")
        print("-" * 40)
        
        try:
            model = HybridMamba(
                in_chans=32,
                patch_size=200,
                out_dim=200,
                d_model=200,
                hybrid_mode=mode
            )
            
            # æµ‹è¯•å‰å‘ä¼ æ’­
            x = torch.randn(2, 32, 4, 200)  # batch_size=2
            
            with torch.no_grad():
                output = model(x)
            
            print(f"âœ… æ¨¡å¼ '{mode}' æµ‹è¯•æˆåŠŸ")
            print(f"   è¾“å…¥å½¢çŠ¶: {x.shape}")
            print(f"   è¾“å‡ºå½¢çŠ¶: {output.shape}")
            
            # è®¡ç®—å‚æ•°é‡
            total_params = sum(p.numel() for p in model.parameters())
            print(f"   æ€»å‚æ•°é‡: {total_params:,}")
            
        except Exception as e:
            print(f"âŒ æ¨¡å¼ '{mode}' æµ‹è¯•å¤±è´¥: {e}")
    
    print("\n" + "=" * 60)
    print("æµ‹è¯•å®Œæˆ")
    print("=" * 60)

if __name__ == "__main__":
    test_hybrid_modes()